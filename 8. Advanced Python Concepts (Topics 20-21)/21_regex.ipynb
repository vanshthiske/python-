{
"cells": [
{
"cell_type": "markdown",
"metadata": {},
"source": [
"# Topic 23: Regular Expressions - Pattern Matching\n",
"\n",
"## Overview\n",
"Regular expressions (regex) are powerful tools for pattern matching, text processing, and data extraction. Master the art of finding and manipulating text patterns.\n",
"\n",
"### What You'll Learn:\n",
"- Basic regex patterns and metacharacters\n",
"- Python's re module functions\n",
"- Groups and capturing\n",
"- Advanced patterns and flags\n",
"- Real-world text processing applications\n",
"- Performance considerations\n",
"\n",
"---"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## 1. Basic Regular Expression Patterns\n",
"\n",
"Understanding fundamental regex syntax:"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Basic regular expression patterns\nimport re\n\nprint(\"Basic Regular Expression Patterns:\")\nprint(\"=\" * 35)\n\n# Basic pattern matching\nprint(\"1. Basic pattern matching:\")\n\n# Literal matching\ntext = \"Hello, World! Welcome to Python programming.\"\npattern = \"Python\"\n\nmatch = re.search(pattern, text)\nif match:\n    print(f\"   Found '{pattern}' at position {match.start()}-{match.end()}\")\n    print(f\"   Matched text: '{match.group()}'\")\nelse:\n    print(f\"   Pattern '{pattern}' not found\")\n\n# Case-sensitive vs case-insensitive\nprint(f\"\\n2. Case sensitivity:\")\ntext_mixed = \"python PYTHON Python PyThOn\"\npattern_case = \"python\"\n\nprint(f\"   Text: {text_mixed}\")\nprint(f\"   Pattern: {pattern_case}\")\n\n# Case-sensitive search (default)\nmatches_case = re.findall(pattern_case, text_mixed)\nprint(f\"   Case-sensitive matches: {matches_case}\")\n\n# Case-insensitive search\nmatches_ignore = re.findall(pattern_case, text_mixed, re.IGNORECASE)\nprint(f\"   Case-insensitive matches: {matches_ignore}\")\n\n# Metacharacters\nprint(f\"\\n3. Basic metacharacters:\")\n\ntext_meta = \"The price is $123.45 and tax is 8.5%\"\n\n# . (dot) - matches any character except newline\nprint(f\"   Text: {text_meta}\")\nprint(f\"   Pattern '.rice': {re.findall(r'.rice', text_meta)}\")\nprint(f\"   Pattern 'p..ce': {re.findall(r'p..ce', text_meta)}\")\n\n# ^ - matches start of string\nstart_matches = [\n    (\"The\", re.search(r'^The', text_meta)),\n    (\"price\", re.search(r'^price', text_meta))\n]\n\nfor pattern, match in start_matches:\n    result = \"Found\" if match else \"Not found\"\n    print(f\"   Pattern '^{pattern}': {result}\")\n\n# $ - matches end of string\nend_text = \"Hello World!\"\nend_matches = [\n    (\"World!\", re.search(r'World!$', end_text)),\n    (\"Hello\", re.search(r'Hello$', end_text))\n]\n\nfor pattern, match in end_matches:\n    result = \"Found\" if match else \"Not found\"\n    print(f\"   Pattern '{pattern}$': {result}\")\n\n# Character classes\nprint(f\"\\n4. Character classes:\")\n\ntext_chars = \"Hello123 World456 Test789!\"\nprint(f\"   Text: {text_chars}\")\n\n# \\d - digits\ndigits = re.findall(r'\\d', text_chars)\nprint(f\"   \\\\d (digits): {digits}\")\n\n# \\d+ - one or more digits\ndigit_groups = re.findall(r'\\d+', text_chars)\nprint(f\"   \\\\d+ (digit groups): {digit_groups}\")\n\n# \\w - word characters (letters, digits, underscore)\nword_chars = re.findall(r'\\w', text_chars)\nprint(f\"   \\\\w (word chars): {word_chars[:10]}...\")  # Show first 10\n\n# \\w+ - word groups\nwords = re.findall(r'\\w+', text_chars)\nprint(f\"   \\\\w+ (words): {words}\")\n\n# \\s - whitespace\nwhitespace = re.findall(r'\\s', text_chars)\nprint(f\"   \\\\s (whitespace): {repr(whitespace)}\")\n\n# Custom character classes\nprint(f\"\\n5. Custom character classes:\")\n\nvowel_text = \"Education is important\"\nprint(f\"   Text: {vowel_text}\")\n\n# [aeiou] - specific characters\nvowels = re.findall(r'[aeiou]', vowel_text.lower())\nprint(f\"   [aeiou] (vowels): {vowels}\")\n\n# [a-z] - character range\nlowercase = re.findall(r'[a-z]', vowel_text)\nprint(f\"   [a-z] (lowercase): {lowercase[:10]}...\")  # Show first 10\n\n# [A-Z] - uppercase range\nuppercase = re.findall(r'[A-Z]', vowel_text)\nprint(f\"   [A-Z] (uppercase): {uppercase}\")\n\n# [0-9] - digit range (same as \\d)\ndigit_range = re.findall(r'[0-9]', \"Age: 25, Score: 98\")\nprint(f\"   [0-9] (digit range): {digit_range}\")\n\n# [^...] - negation (NOT)\nnon_vowels = re.findall(r'[^aeiou\\s]', vowel_text.lower())\nprint(f\"   [^aeiou\\\\s] (consonants): {non_vowels}\")\n\n# Quantifiers\nprint(f\"\\n6. Quantifiers:\")\n\nquant_text = \"a aa aaa aaaa b bb bbb\"\nprint(f\"   Text: {quant_text}\")\n\n# * - zero or more\nstar_matches = re.findall(r'a*', quant_text)\nprint(f\"   a* (zero or more a): {star_matches[:10]}...\")  # Many empty matches\n\n# + - one or more\nplus_matches = re.findall(r'a+', quant_text)\nprint(f\"   a+ (one or more a): {plus_matches}\")\n\n# ? - zero or one\nquestion_matches = re.findall(r'a?', quant_text)\nprint(f\"   a? (zero or one a): {question_matches[:10]}...\")  # Many matches\n\n# {n} - exactly n\nexact_matches = re.findall(r'a{3}', quant_text)\nprint(f\"   a{{3}} (exactly 3 a's): {exact_matches}\")\n\n# {n,m} - between n and m\nrange_matches = re.findall(r'a{2,3}', quant_text)\nprint(f\"   a{{2,3}} (2-3 a's): {range_matches}\")\n\n# {n,} - n or more\nmin_matches = re.findall(r'a{2,}', quant_text)\nprint(f\"   a{{2,}} (2 or more a's): {min_matches}\")\n\n# Practical examples\nprint(f\"\\n7. Practical pattern examples:\")\n\n# Email pattern (basic)\nemail_text = \"Contact: john@example.com or support@company.org\"\nemail_pattern = r'\\w+@\\w+\\.\\w+'\nemails = re.findall(email_pattern, email_text)\nprint(f\"   Text: {email_text}\")\nprint(f\"   Email pattern: {emails}\")\n\n# Phone number pattern\nphone_text = \"Call 123-456-7890 or (555) 123-4567\"\nphone_pattern = r'\\(?\\d{3}\\)?[-\\s]?\\d{3}[-\\s]?\\d{4}'\nphones = re.findall(phone_pattern, phone_text)\nprint(f\"   Text: {phone_text}\")\nprint(f\"   Phone numbers: {phones}\")\n\n# URL pattern (basic)\nurl_text = \"Visit https://www.example.com or http://test.org/path\"\nurl_pattern = r'https?://[\\w.-]+(?:/[\\w.-]*)*'\nurls = re.findall(url_pattern, url_text)\nprint(f\"   Text: {url_text}\")\nprint(f\"   URLs: {urls}\")\n\n# Time pattern\ntime_text = \"Meeting at 09:30, lunch at 12:45, finish by 17:00\"\ntime_pattern = r'\\d{1,2}:\\d{2}'\ntimes = re.findall(time_pattern, time_text)\nprint(f\"   Text: {time_text}\")\nprint(f\"   Times: {times}\")\n\n# Greedy vs non-greedy matching\nprint(f\"\\n8. Greedy vs non-greedy:\")\n\nhtml_text = \"<div>Hello</div> and <span>World</span>\"\nprint(f\"   HTML text: {html_text}\")\n\n# Greedy (default) - matches as much as possible\ngreedy_pattern = r'<.*>'\ngreedy_match = re.findall(greedy_pattern, html_text)\nprint(f\"   Greedy <.*>: {greedy_match}\")\n\n# Non-greedy - matches as little as possible\nnon_greedy_pattern = r'<.*?>'\nnon_greedy_match = re.findall(non_greedy_pattern, html_text)\nprint(f\"   Non-greedy <.*?>: {non_greedy_match}\")\n\n# Extract content between tags\ncontent_pattern = r'<[^>]+>([^<]*)</[^>]+>'\ncontent_matches = re.findall(content_pattern, html_text)\nprint(f\"   Content between tags: {content_matches}\")"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## 2. Python's re Module Functions\n",
"\n",
"Understanding the main functions in Python's re module:"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Python's re module functions\nimport re\n\nprint(\"Python's re Module Functions:\")\nprint(\"=\" * 29)\n\n# Sample text for demonstrations\nsample_text = \"\"\"John Doe: 123-456-7890, john.doe@email.com\nJane Smith: (555) 123-4567, jane@company.org  \nBob Wilson: 987.654.3210, bob_wilson@test.net\nAlice Brown: 444-555-6666, alice.brown@domain.co.uk\"\"\"\n\nprint(f\"Sample text:\")\nprint(f\"{sample_text}\")\n\n# re.search() - find first match\nprint(f\"\\n1. re.search() - find first match:\")\n\nphone_pattern = r'\\d{3}[.-]\\d{3}[.-]\\d{4}'\nfirst_phone = re.search(phone_pattern, sample_text)\n\nif first_phone:\n    print(f\"   First phone found: '{first_phone.group()}'\")\n    print(f\"   Position: {first_phone.start()}-{first_phone.end()}\")\n    print(f\"   Full match object: {first_phone}\")\nelse:\n    print(f\"   No phone numbers found\")\n\n# re.match() - match at string beginning\nprint(f\"\\n2. re.match() - match at string beginning:\")\n\nname_pattern = r'\\w+\\s+\\w+'\nstart_match = re.match(name_pattern, sample_text)\n\nif start_match:\n    print(f\"   Match at start: '{start_match.group()}'\")\nelse:\n    print(f\"   No match at string beginning\")\n\n# Test with different starting text\ntest_string = \"Alice Johnson is here\"\nmatch_test = re.match(name_pattern, test_string)\nprint(f\"   Testing '{test_string[:20]}...': {match_test.group() if match_test else 'No match'}\")\n\n# re.findall() - find all matches\nprint(f\"\\n3. re.findall() - find all matches:\")\n\n# Find all phone numbers\nall_phones = re.findall(phone_pattern, sample_text)\nprint(f\"   All phones: {all_phones}\")\n\n# Find all email addresses\nemail_pattern = r'[\\w.-]+@[\\w.-]+\\.[\\w]+'\nall_emails = re.findall(email_pattern, sample_text)\nprint(f\"   All emails: {all_emails}\")\n\n# Find all names (assuming they're at line starts)\nname_pattern_full = r'^(\\w+\\s+\\w+):'\nall_names = re.findall(name_pattern_full, sample_text, re.MULTILINE)\nprint(f\"   All names: {all_names}\")\n\n# re.finditer() - find all matches as match objects\nprint(f\"\\n4. re.finditer() - find all match objects:\")\n\nfor i, match in enumerate(re.finditer(phone_pattern, sample_text), 1):\n    print(f\"   Phone {i}: '{match.group()}' at position {match.start()}-{match.end()}\")\n\n# re.split() - split string by pattern\nprint(f\"\\n5. re.split() - split by pattern:\")\n\n# Split by various delimiters\nmixed_delim_text = \"apple,banana;orange:grape|kiwi\"\ndelim_pattern = r'[,;:|]'\nfruits = re.split(delim_pattern, mixed_delim_text)\nprint(f\"   Text: {mixed_delim_text}\")\nprint(f\"   Split by [,;:|]: {fruits}\")\n\n# Split with limit\nlimited_split = re.split(delim_pattern, mixed_delim_text, maxsplit=2)\nprint(f\"   Split with limit 2: {limited_split}\")\n\n# Split by whitespace (multiple spaces/tabs)\nwhitespace_text = \"word1    word2\\tword3   word4\"\nwhitespace_split = re.split(r'\\s+', whitespace_text)\nprint(f\"   Text: '{whitespace_text}'\")\nprint(f\"   Split by whitespace: {whitespace_split}\")\n\n# re.sub() - substitute matches\nprint(f\"\\n6. re.sub() - substitute matches:\")\n\n# Replace phone number formats\nphone_text = \"Call 123-456-7890 or (555) 123-4567\"\nprint(f\"   Original: {phone_text}\")\n\n# Standardize phone format\nstandardized = re.sub(r'\\(?\\(?([0-9]{3})\\)?[-.]?([0-9]{3})[-.]?([0-9]{4})', \n                     r'(\\1) \\2-\\3', phone_text)\nprint(f\"   Standardized: {standardized}\")\n\n# Replace with function\ndef phone_formatter(match):\n    \"\"\"Custom phone formatting function\"\"\"\n    full_match = match.group(0)\n    digits_only = re.sub(r'\\D', '', full_match)\n    if len(digits_only) == 10:\n        return f\"{digits_only[:3]}-{digits_only[3:6]}-{digits_only[6:]}\"\n    return full_match\n\ncustom_format = re.sub(r'\\(?\\d{3}\\)?[-\\s]?\\d{3}[-\\s]?\\d{4}', phone_formatter, phone_text)\nprint(f\"   Custom format: {custom_format}\")\n\n# Count replacements\nsensitive_text = \"This is SENSITIVE data with sensitive information\"\ncleaned_text, count = re.subn(r'sensitive', '[REDACTED]', sensitive_text, flags=re.IGNORECASE)\nprint(f\"   Original: {sensitive_text}\")\nprint(f\"   Cleaned: {cleaned_text}\")\nprint(f\"   Replacements made: {count}\")\n\n# re.compile() - compile patterns for reuse\nprint(f\"\\n7. re.compile() - compile for performance:\")\n\n# Compile frequently used patterns\nemail_regex = re.compile(r'[\\w.-]+@[\\w.-]+\\.[\\w]+')\nphone_regex = re.compile(r'\\(?\\d{3}\\)?[-\\s]?\\d{3}[-\\s]?\\d{4}')\n\n# Use compiled patterns\ntest_texts = [\n    \"Contact: alice@example.com, phone: 555-1234\",\n    \"Email support@company.org or call (123) 456-7890\",\n    \"No contact info in this text\"\n]\n\nfor text in test_texts:\n    emails_found = email_regex.findall(text)\n    phones_found = phone_regex.findall(text)\n    print(f\"   Text: '{text[:30]}...'\")\n    print(f\"     Emails: {emails_found}\")\n    print(f\"     Phones: {phones_found}\")\n\n# Pattern flags\nprint(f\"\\n8. Pattern flags:\")\n\nflag_text = \"\"\"Hello World\nPython Programming\nREGEX Patterns\"\"\"\n\nprint(f\"   Text: {repr(flag_text)}\")\n\n# IGNORECASE flag\nignore_case_matches = re.findall(r'python', flag_text, re.IGNORECASE)\nprint(f\"   IGNORECASE 'python': {ignore_case_matches}\")\n\n# MULTILINE flag - ^ and $ match line boundaries\nmultiline_matches = re.findall(r'^\\w+', flag_text, re.MULTILINE)\nprint(f\"   MULTILINE '^\\\\w+': {multiline_matches}\")\n\n# DOTALL flag - . matches newlines\ndotall_match = re.search(r'Hello.*Patterns', flag_text, re.DOTALL)\nprint(f\"   DOTALL 'Hello.*Patterns': {'Found' if dotall_match else 'Not found'}\")\n\n# VERBOSE flag - allow comments and whitespace in pattern\nverbose_pattern = re.compile(r\"\"\"\n    \\d{3}      # Area code\n    [-.]       # Separator\n    \\d{3}      # Exchange\n    [-.]       # Separator  \n    \\d{4}      # Number\n    \"\"\", re.VERBOSE)\n\nverbose_test = \"Phone: 123-456-7890\"\nverbose_match = verbose_pattern.search(verbose_test)\nprint(f\"   VERBOSE pattern match: {'Found' if verbose_match else 'Not found'}\")\n\n# Multiple flags\nmulti_flag_pattern = re.compile(r'^hello.*world', re.IGNORECASE | re.DOTALL | re.MULTILINE)\nmulti_test = \"HELLO beautiful\\nWORLD\"\nmulti_match = multi_flag_pattern.search(multi_test)\nprint(f\"   Multiple flags: {'Found' if multi_match else 'Not found'}\")\n\n# Performance comparison\nprint(f\"\\n9. Performance: compiled vs uncompiled:\")\nimport time\n\ntest_pattern = r'\\b\\w{5,}\\b'  # Words 5+ characters\nlarge_text = \"Python programming is awesome and powerful \" * 1000\n\n# Uncompiled pattern\nstart = time.time()\nfor _ in range(100):\n    re.findall(test_pattern, large_text)\nuncompiled_time = time.time() - start\n\n# Compiled pattern\ncompiled_pattern = re.compile(test_pattern)\nstart = time.time()\nfor _ in range(100):\n    compiled_pattern.findall(large_text)\ncompiled_time = time.time() - start\n\nprint(f\"   Uncompiled: {uncompiled_time:.4f} seconds\")\nprint(f\"   Compiled: {compiled_time:.4f} seconds\")\nprint(f\"   Speedup: {uncompiled_time/compiled_time:.1f}x faster\")\n\nprint(f\"\\n10. Function summary:\")\nprint(f\"   re.search(): Find first match\")\nprint(f\"   re.match(): Match at string start\")\nprint(f\"   re.findall(): Find all matches as strings\")\nprint(f\"   re.finditer(): Find all matches as match objects\")\nprint(f\"   re.split(): Split string by pattern\")\nprint(f\"   re.sub(): Replace matches\")\nprint(f\"   re.subn(): Replace matches and return count\")\nprint(f\"   re.compile(): Compile pattern for reuse\")"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## 3. Groups and Capturing\n",
"\n",
"Using parentheses to capture parts of matches:"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Groups and capturing\nimport re\nfrom datetime import datetime\n\nprint(\"Groups and Capturing:\")\nprint(\"=\" * 21)\n\n# Basic groups\nprint(\"1. Basic groups with parentheses:\")\n\n# Extract parts of a phone number\nphone_text = \"Call me at (555) 123-4567 for more info\"\nphone_pattern = r'\\((\\d{3})\\)\\s(\\d{3})-(\\d{4})'\n\nmatch = re.search(phone_pattern, phone_text)\nif match:\n    print(f\"   Text: {phone_text}\")\n    print(f\"   Full match: {match.group(0)}\")\n    print(f\"   Area code: {match.group(1)}\")\n    print(f\"   Exchange: {match.group(2)}\")\n    print(f\"   Number: {match.group(3)}\")\n    print(f\"   All groups: {match.groups()}\")\n\n# Extract email components\nemail_text = \"Contact john.doe@company.co.uk for support\"\nemail_pattern = r'([\\w.-]+)@([\\w.-]+)\\.([\\w]+)'\n\nemail_match = re.search(email_pattern, email_text)\nif email_match:\n    print(f\"\\n   Email: {email_match.group(0)}\")\n    print(f\"   Username: {email_match.group(1)}\")\n    print(f\"   Domain: {email_match.group(2)}\")\n    print(f\"   TLD: {email_match.group(3)}\")\n\n# Multiple groups with findall\nprint(f\"\\n2. Multiple groups with findall:\")\n\nlog_data = \"\"\"2024-01-15 10:30:15 INFO User logged in\n2024-01-15 10:35:22 ERROR Database connection failed\n2024-01-15 10:40:08 WARNING Low disk space\n2024-01-15 10:45:33 INFO User logged out\"\"\"\n\nlog_pattern = r'(\\d{4}-\\d{2}-\\d{2})\\s(\\d{2}:\\d{2}:\\d{2})\\s(\\w+)\\s(.+)'\nlog_matches = re.findall(log_pattern, log_data)\n\nprint(f\"   Log entries:\")\nfor date, time, level, message in log_matches:\n    print(f\"   {date} at {time}: [{level}] {message}\")\n\n# Named groups\nprint(f\"\\n3. Named groups (?P<name>pattern):\")\n\n# More readable group names\ndate_pattern = r'(?P<year>\\d{4})-(?P<month>\\d{2})-(?P<day>\\d{2})'\ndate_text = \"Today's date is 2024-03-15\"\n\ndate_match = re.search(date_pattern, date_text)\nif date_match:\n    print(f\"   Text: {date_text}\")\n    print(f\"   Year: {date_match.group('year')}\")\n    print(f\"   Month: {date_match.group('month')}\")\n    print(f\"   Day: {date_match.group('day')}\")\n    print(f\"   Full date: {date_match.group(0)}\")\n    print(f\"   Group dict: {date_match.groupdict()}\")\n\n# Complex named groups example\nurl_pattern = r'(?P<protocol>https?)://(?P<domain>[\\w.-]+)(?P<port>:\\d+)?(?P<path>/[\\w/-]*)?(?P<query>\\?[\\w=&-]*)?'\ntest_urls = [\n    \"https://www.example.com/path/to/page?id=123&type=test\",\n    \"http://localhost:8080/admin\",\n    \"https://api.service.com/v1/users\"\n]\n\nprint(f\"\\n   URL parsing with named groups:\")\nfor url in test_urls:\n    match = re.search(url_pattern, url)\n    if match:\n        print(f\"   URL: {url}\")\n        for name, value in match.groupdict().items():\n            if value:\n                print(f\"     {name}: {value}\")\n        print()\n\n# Non-capturing groups\nprint(f\"4. Non-capturing groups (?:pattern):\")\n\n# Group for alternation without capturing\nfile_pattern_capturing = r'(\\w+)\\.(jpg|png|gif)'  # Captures extension\nfile_pattern_non_capturing = r'(\\w+)\\.(?:jpg|png|gif)'  # Doesn't capture extension\n\nfile_text = \"images: photo.jpg, icon.png, banner.gif\"\n\ncapturing_matches = re.findall(file_pattern_capturing, file_text)\nnon_capturing_matches = re.findall(file_pattern_non_capturing, file_text)\n\nprint(f\"   Text: {file_text}\")\nprint(f\"   Capturing groups: {capturing_matches}\")\nprint(f\"   Non-capturing groups: {non_capturing_matches}\")\n\n# Backreferences\nprint(f\"\\n5. Backreferences \\\\1, \\\\2, etc.:\")\n\n# Find repeated words\nrepeated_word_text = \"This is is a test test with repeated words words\"\nrepeated_pattern = r'\\b(\\w+)\\s+\\1\\b'\n\nrepeated_matches = re.findall(repeated_pattern, repeated_word_text)\nprint(f\"   Text: {repeated_word_text}\")\nprint(f\"   Repeated words: {repeated_matches}\")\n\n# Find and highlight repeated words\nhighlighted = re.sub(repeated_pattern, r'[\\1-REPEATED]', repeated_word_text)\nprint(f\"   Highlighted: {highlighted}\")\n\n# HTML tag matching with backreferences\nhtml_text = \"<div>Content</div> and <span>More content</span> but <p>Unclosed div\"\nmatching_tags_pattern = r'<(\\w+)>([^<]*)</\\1>'\n\nmatching_tags = re.findall(matching_tags_pattern, html_text)\nprint(f\"\\n   HTML: {html_text}\")\nprint(f\"   Matching tags: {matching_tags}\")\n\n# Conditional groups\nprint(f\"\\n6. Conditional patterns:\")\n\n# Optional groups\noptional_pattern = r'\\d{3}(-?)\\d{3}\\1\\d{4}'  # Consistent separator\nphone_tests = [\"123-456-7890\", \"1234567890\", \"123.456.7890\", \"123-456.7890\"]\n\nprint(f\"   Testing consistent separator pattern:\")\nfor phone in phone_tests:\n    match = re.search(optional_pattern, phone)\n    result = \"Match\" if match else \"No match\"\n    print(f\"   {phone}: {result}\")\n\n# Lookahead and lookbehind\nprint(f\"\\n7. Lookahead and lookbehind:\")\n\n# Positive lookahead (?=pattern)\npassword_text = \"MyPassword123\"\npassword_with_digit = r'\\w*(?=\\d)\\w*'  # Words containing digits\n\ndigit_match = re.search(password_with_digit, password_text)\nprint(f\"   Text: {password_text}\")\nprint(f\"   Contains digit: {'Yes' if digit_match else 'No'}\")\n\n# Extract words followed by specific punctuation\ntext_with_punct = \"Hello, World! How are you? Fine, thanks.\"\nwords_before_punct = re.findall(r'\\w+(?=[,.!?])', text_with_punct)\nprint(f\"   Text: {text_with_punct}\")\nprint(f\"   Words before punctuation: {words_before_punct}\")\n\n# Negative lookahead (?!pattern)\nfilename_text = \"script.py config.txt data.csv backup.py\"\nnon_python_files = re.findall(r'\\w+\\.(?!py)\\w+', filename_text)\nprint(f\"   Files: {filename_text}\")\nprint(f\"   Non-Python files: {non_python_files}\")\n\n# Lookbehind examples\ncurrency_text = \"Price: $19.99, Cost: â‚¬25.50, Tax: Â£5.00\"\ncurrency_amounts = re.findall(r'(?<=[\\$â‚¬Â£])\\d+\\.\\d{2}', currency_text)\nprint(f\"   Currency text: {currency_text}\")\nprint(f\"   Amounts: {currency_amounts}\")\n\n# Complex grouping example: parsing CSV-like data\nprint(f\"\\n8. Complex parsing example:\")\n\ncsv_data = '''\"John Doe\",25,\"Software Engineer\",\"New York\"\n\"Jane Smith\",30,\"Data Scientist\",\"San Francisco\"\n\"Bob Wilson\",28,\"Designer\",\"Los Angeles\"'''\n\n# Pattern to parse CSV with quoted fields\ncsv_pattern = r'\"([^\"]*)\",([^,]+),\"([^\"]*)\",\"([^\"]*)\")'\ncsv_matches = re.findall(csv_pattern, csv_data)\n\nprint(f\"   CSV data parsing:\")\nfor name, age, job, city in csv_matches:\n    print(f\"   Name: {name}, Age: {age}, Job: {job}, City: {city}\")\n\n# Extract and transform with groups\nprint(f\"\\n9. Transform with groups:\")\n\namerican_dates = \"Event on 03/15/2024 and meeting on 12/25/2024\"\ndate_transform_pattern = r'(\\d{2})/(\\d{2})/(\\d{4})'\n\n# Transform MM/DD/YYYY to DD-MM-YYYY\neuropean_dates = re.sub(date_transform_pattern, r'\\2-\\1-\\3', american_dates)\nprint(f\"   American format: {american_dates}\")\nprint(f\"   European format: {european_dates}\")\n\n# Advanced substitution with function\ndef date_converter(match):\n    \"\"\"Convert date format and validate\"\"\"\n    month, day, year = match.groups()\n    try:\n        # Validate date\n        date_obj = datetime(int(year), int(month), int(day))\n        # Return formatted date\n        return date_obj.strftime(\"%d %B %Y\")\n    except ValueError:\n        return match.group(0)  # Return original if invalid\n\nreadable_dates = re.sub(date_transform_pattern, date_converter, american_dates)\nprint(f\"   Readable format: {readable_dates}\")\n\nprint(f\"\\n10. Groups summary:\")\nprint(f\"   (pattern): Capturing group\")\nprint(f\"   (?P<name>pattern): Named capturing group\")\nprint(f\"   (?:pattern): Non-capturing group\")\nprint(f\"   \\\\1, \\\\2: Backreferences to captured groups\")\nprint(f\"   (?=pattern): Positive lookahead\")\nprint(f\"   (?!pattern): Negative lookahead\")\nprint(f\"   (?<=pattern): Positive lookbehind\")\nprint(f\"   (?<!pattern): Negative lookbehind\")"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## 4. Real-World Applications\n",
"\n",
"Practical regex applications for common tasks:"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Real-world regex applications\nimport re\nimport json\nfrom collections import Counter\n\nprint(\"Real-World Regex Applications:\")\nprint(\"=\" * 31)\n\n# Email validation\nprint(\"1. Email validation:\")\n\ndef validate_email(email):\n    \"\"\"Comprehensive email validation\"\"\"\n    # More comprehensive email pattern\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return re.match(pattern, email) is not None\n\ntest_emails = [\n    \"valid@example.com\",\n    \"user.name+tag@domain.co.uk\", \n    \"invalid.email\",\n    \"@invalid.com\",\n    \"valid123@test-domain.org\",\n    \"spaces @invalid.com\",\n    \"toolongextension@example.toolongextension\"\n]\n\nprint(f\"   Email validation results:\")\nfor email in test_emails:\n    is_valid = validate_email(email)\n    status = \"âœ“\" if is_valid else \"âœ—\"\n    print(f\"   {status} {email}\")\n\n# Phone number normalization\nprint(f\"\\n2. Phone number normalization:\")\n\ndef normalize_phone(phone):\n    \"\"\"Normalize various phone number formats\"\"\"\n    # Extract digits only\n    digits = re.sub(r'\\D', '', phone)\n    \n    if len(digits) == 10:\n        return f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n    elif len(digits) == 11 and digits[0] == '1':\n        return f\"+1 ({digits[1:4]}) {digits[4:7]}-{digits[7:]}\"\n    else:\n        return \"Invalid phone number\"\n\nphone_formats = [\n    \"555-123-4567\",\n    \"(555) 123-4567\",\n    \"5551234567\",\n    \"1-555-123-4567\",\n    \"+1 (555) 123-4567\",\n    \"555.123.4567\",\n    \"12345\"  # Invalid\n]\n\nprint(f\"   Phone normalization:\")\nfor phone in phone_formats:\n    normalized = normalize_phone(phone)\n    print(f\"   {phone:20} -> {normalized}\")\n\n# Log file analysis\nprint(f\"\\n3. Log file analysis:\")\n\nlog_content = \"\"\"2024-01-15 10:30:15 INFO [UserService] User 'alice' logged in from 192.168.1.100\n2024-01-15 10:35:22 ERROR [DatabaseService] Connection timeout to db.example.com:5432\n2024-01-15 10:40:08 WARNING [MemoryManager] Memory usage at 85%\n2024-01-15 10:45:33 INFO [UserService] User 'bob' logged out\n2024-01-15 10:50:45 ERROR [ApiService] HTTP 500 error on /api/users endpoint\n2024-01-15 10:55:12 INFO [UserService] User 'charlie' logged in from 10.0.0.50\"\"\"\n\ndef analyze_logs(log_text):\n    \"\"\"Extract structured information from logs\"\"\"\n    # Comprehensive log pattern\n    pattern = r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})\\s(?P<level>\\w+)\\s\\[(?P<service>\\w+)\\]\\s(?P<message>.+)'\n    \n    matches = re.finditer(pattern, log_text)\n    entries = []\n    \n    for match in matches:\n        entry = match.groupdict()\n        \n        # Extract additional info from message\n        if 'logged in' in entry['message']:\n            user_match = re.search(r\"User '(\\w+)'\", entry['message'])\n            ip_match = re.search(r'from ([\\d.]+)', entry['message'])\n            entry['action'] = 'login'\n            entry['user'] = user_match.group(1) if user_match else None\n            entry['ip'] = ip_match.group(1) if ip_match else None\n        \n        elif 'logged out' in entry['message']:\n            user_match = re.search(r\"User '(\\w+)'\", entry['message'])\n            entry['action'] = 'logout'\n            entry['user'] = user_match.group(1) if user_match else None\n        \n        entries.append(entry)\n    \n    return entries\n\nlog_entries = analyze_logs(log_content)\n\nprint(f\"   Log analysis results:\")\nfor entry in log_entries:\n    print(f\"   {entry['timestamp']} [{entry['level']}] {entry['service']}: {entry['message'][:50]}...\")\n    if 'user' in entry and entry['user']:\n        print(f\"     -> User: {entry['user']}, Action: {entry.get('action', 'N/A')}\")\n\n# Count log levels\nlog_levels = Counter(entry['level'] for entry in log_entries)\nprint(f\"\\n   Log level summary: {dict(log_levels)}\")\n\n# Web scraping - extract links\nprint(f\"\\n4. HTML link extraction:\")\n\nhtml_content = \"\"\"\n<html>\n<body>\n    <a href=\"https://www.example.com\">Example Site</a>\n    <a href=\"/internal/page\">Internal Link</a>\n    <a href=\"mailto:contact@example.com\">Email Us</a>\n    <a href=\"https://api.service.com/v1/data\">API Endpoint</a>\n    <img src=\"image.jpg\" alt=\"Image\">\n    <link rel=\"stylesheet\" href=\"styles.css\">\n</body>\n</html>\n\"\"\"\n\ndef extract_links(html):\n    \"\"\"Extract different types of links from HTML\"\"\"\n    results = {\n        'external_links': [],\n        'internal_links': [],\n        'email_links': [],\n        'images': [],\n        'stylesheets': []\n    }\n    \n    # External HTTP/HTTPS links\n    external_pattern = r'<a\\s+href=\"(https?://[^\"]+)\"[^>]*>([^<]+)</a>'\n    results['external_links'] = re.findall(external_pattern, html)\n    \n    # Internal links (starting with /)\n    internal_pattern = r'<a\\s+href=\"(/[^\"]+)\"[^>]*>([^<]+)</a>'\n    results['internal_links'] = re.findall(internal_pattern, html)\n    \n    # Email links\n    email_pattern = r'<a\\s+href=\"mailto:([^\"]+)\"[^>]*>([^<]+)</a>'\n    results['email_links'] = re.findall(email_pattern, html)\n    \n    # Images\n    img_pattern = r'<img\\s+src=\"([^\"]+)\"[^>]*alt=\"([^\"]+)\"[^>]*>'\n    results['images'] = re.findall(img_pattern, html)\n    \n    # Stylesheets\n    css_pattern = r'<link\\s+rel=\"stylesheet\"\\s+href=\"([^\"]+)\"[^>]*>'\n    results['stylesheets'] = re.findall(css_pattern, html)\n    \n    return results\n\nlinks = extract_links(html_content)\nprint(f\"   Link extraction results:\")\nfor link_type, link_list in links.items():\n    if link_list:\n        print(f\"   {link_type.replace('_', ' ').title()}:\")\n        for link in link_list:\n            if isinstance(link, tuple):\n                print(f\"     URL: {link[0]}, Text: {link[1]}\")\n            else:\n                print(f\"     {link}\")\n\n# Data cleaning and validation\nprint(f\"\\n5. Data cleaning and validation:\")\n\ndef clean_and_validate_data(raw_data):\n    \"\"\"Clean and validate mixed data\"\"\"\n    results = {\n        'cleaned_data': [],\n        'errors': []\n    }\n    \n    for i, item in enumerate(raw_data):\n        cleaned_item = {}\n        \n        # Clean name (remove extra spaces, capitalize)\n        if 'name' in item:\n            name = re.sub(r'\\s+', ' ', item['name'].strip())\n            if re.match(r'^[a-zA-Z\\s]+$', name):\n                cleaned_item['name'] = name.title()\n            else:\n                results['errors'].append(f\"Row {i}: Invalid name format\")\n        \n        # Validate and clean email\n        if 'email' in item:\n            email = item['email'].strip().lower()\n            if re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', email):\n                cleaned_item['email'] = email\n            else:\n                results['errors'].append(f\"Row {i}: Invalid email format\")\n        \n        # Clean phone number\n        if 'phone' in item:\n            phone = re.sub(r'\\D', '', item['phone'])\n            if len(phone) == 10:\n                cleaned_item['phone'] = f\"({phone[:3]}) {phone[3:6]}-{phone[6:]}\"\n            else:\n                results['errors'].append(f\"Row {i}: Invalid phone number\")\n        \n        # Validate age\n        if 'age' in item:\n            age_match = re.search(r'\\d+', str(item['age']))\n            if age_match:\n                age = int(age_match.group())\n                if 0 <= age <= 120:\n                    cleaned_item['age'] = age\n                else:\n                    results['errors'].append(f\"Row {i}: Age out of range\")\n            else:\n                results['errors'].append(f\"Row {i}: Invalid age format\")\n        \n        if cleaned_item:  # Only add if some data was cleaned successfully\n            results['cleaned_data'].append(cleaned_item)\n    \n    return results\n\n# Sample messy data\nmessy_data = [\n    {'name': 'john   doe', 'email': 'JOHN@EXAMPLE.COM', 'phone': '555-123-4567', 'age': '25'},\n    {'name': 'jane smith123', 'email': 'invalid-email', 'phone': '5551234567', 'age': 30},\n    {'name': '  alice brown  ', 'email': 'alice@company.org', 'phone': '(555) 987-6543', 'age': '200'},\n    {'name': 'bob wilson', 'email': 'bob@test.com', 'phone': '12345', 'age': 'twenty-five'}\n]\n\ncleaning_results = clean_and_validate_data(messy_data)\n\nprint(f\"   Data cleaning results:\")\nprint(f\"   Cleaned records: {len(cleaning_results['cleaned_data'])}\")\nfor record in cleaning_results['cleaned_data']:\n    print(f\"     {record}\")\n\nprint(f\"\\n   Errors encountered:\")\nfor error in cleaning_results['errors']:\n    print(f\"     {error}\")\n\n# Text analysis - extract mentions and hashtags\nprint(f\"\\n6. Social media text analysis:\")\n\nsocial_media_posts = [\n    \"Great meeting with @john_doe and @jane_smith! #productivity #teamwork\",\n    \"Check out this article: https://example.com/article #tech #innovation\",\n    \"Thanks to @alice for the help with #python programming! ðŸ\",\n    \"Looking forward to #conference2024 @tech_event #networking\"\n]\n\ndef analyze_social_text(posts):\n    \"\"\"Extract social media elements\"\"\"\n    analysis = {\n        'mentions': Counter(),\n        'hashtags': Counter(),\n        'urls': [],\n        'emojis': []\n    }\n    \n    for post in posts:\n        # Extract mentions (@username)\n        mentions = re.findall(r'@([\\w_]+)', post)\n        analysis['mentions'].update(mentions)\n        \n        # Extract hashtags (#tag)\n        hashtags = re.findall(r'#([\\w_]+)', post)\n        analysis['hashtags'].update(hashtags)\n        \n        # Extract URLs\n        urls = re.findall(r'https?://[\\w.-]+(?:/[\\w.-]*)*', post)\n        analysis['urls'].extend(urls)\n        \n        # Extract emojis (basic Unicode detection)\n        emojis = re.findall(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]', post)\n        analysis['emojis'].extend(emojis)\n    \n    return analysis\n\nsocial_analysis = analyze_social_text(social_media_posts)\n\nprint(f\"   Social media analysis:\")\nprint(f\"   Top mentions: {dict(social_analysis['mentions'].most_common(3))}\")\nprint(f\"   Top hashtags: {dict(social_analysis['hashtags'].most_common(3))}\")\nprint(f\"   URLs found: {social_analysis['urls']}\")\nprint(f\"   Emojis: {social_analysis['emojis']}\")\n\nprint(f\"\\n7. Regex best practices for real-world use:\")\nprint(f\"   âœ“ Validate inputs before processing\")\nprint(f\"   âœ“ Use specific patterns rather than overly broad ones\")\nprint(f\"   âœ“ Compile patterns for repeated use\")\nprint(f\"   âœ“ Handle edge cases and invalid inputs\")\nprint(f\"   âœ“ Test patterns with various input formats\")\nprint(f\"   âœ“ Document complex patterns with comments\")\nprint(f\"   âš ï¸  Remember: regex isn't always the best tool\")\nprint(f\"   âš ï¸  For HTML/XML parsing, consider dedicated parsers\")\nprint(f\"   âš ï¸  Be careful with user-provided regex patterns\")"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## Summary\n",
"\n",
"In this notebook, you learned about:\n",
"\n",
"âœ… **Basic Patterns**: Metacharacters, character classes, quantifiers  \n",
"âœ… **re Module Functions**: search(), findall(), sub(), compile() and their uses  \n",
"âœ… **Groups and Capturing**: Parentheses, named groups, backreferences  \n",
"âœ… **Advanced Features**: Lookahead/lookbehind, flags, non-capturing groups  \n",
"âœ… **Real-World Applications**: Email validation, log analysis, data cleaning  \n",
"âœ… **Performance**: Compiled patterns and optimization techniques  \n",
"\n",
"### Key Takeaways:\n",
"1. Regular expressions are powerful for pattern matching and text processing\n",
"2. Use specific patterns rather than overly broad ones\n",
"3. Compile patterns with re.compile() for repeated use\n",
"4. Named groups make complex patterns more readable\n",
"5. Test regex patterns thoroughly with edge cases\n",
"6. Consider alternatives like dedicated parsers for complex formats\n",
"\n",
"### Next Topic: 24_context_managers.ipynb\n",
"Learn about context managers and the 'with' statement for resource management."
]
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.8.5"
}
},
"nbformat": 4,
"nbformat_minor": 4
}
